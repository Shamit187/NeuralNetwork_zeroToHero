{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as torchFunc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"names.txt\", 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(''.join(words))))\n",
    "char_to_int = {s:i+1 for i,s in enumerate(characters)}\n",
    "char_to_int['.'] = 0\n",
    "int_to_char = {i:s for s,i in char_to_int.items()}\n",
    "print(int_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a database to train on database.<br>\n",
    "Will have context and output.<br>\n",
    "For emma, possible database is (given block size is 3)\n",
    "<ul>\n",
    "<li>... -> e</li>\n",
    "<li>..e -> m</li>\n",
    "<li>.em -> m</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3\n",
    "context_set, result_set = [], []\n",
    "\n",
    "for word in words:\n",
    "    context = [0]*block_size # '...' -> initial context\n",
    "\n",
    "    for character in word + '.':\n",
    "        result = char_to_int[character]\n",
    "        context_set.append(context)\n",
    "        result_set.append(result)\n",
    "        \n",
    "        # print(''.join(int_to_char[i] for i in context), \"-->\", character)\n",
    "\n",
    "        context = context[1:] + [result]\n",
    "\n",
    "X = torch.tensor(context_set)\n",
    "Y = torch.tensor(result_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_up = torch.randn((27, 2))\n",
    "# look_up[5]\n",
    "# torchFunc.one_hot(torch.tensor(5), num_classes=27).float() @ look_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Embedding strips down dimension</h3>\n",
    "In our case, we have 27 dimension, 27 possible character\n",
    "We strip it to 2 dimension\n",
    "\n",
    "After embedding calculation, we need a way to look up table of some sort, \n",
    "that can take any character and output that embedded value\n",
    "\n",
    "In our case, look_up is that table\n",
    "\n",
    "<h3>We can access look up in two ways</h3>\n",
    "look_up[ix] to get the necessary vector\n",
    "also we can do this\n",
    "look_up matmul one_hot(ix)\n",
    "\n",
    "Both results in same stuff... only this time, \n",
    "the entire look_up then also becomes a part of the neural net \n",
    "and can be used as weights of the first layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Now actual algorithm</h3>\n",
    "\n",
    "input is 3 element context, each is embedded to 2D vector... <br>\n",
    "input is 6 dimensional<br>\n",
    "output hyper parameter... we choose 100 just because<br>\n",
    "bias adds to all output so 100 dimension<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_1 = torch.randn((6, 100))\n",
    "bias_1 = torch.randn((100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
